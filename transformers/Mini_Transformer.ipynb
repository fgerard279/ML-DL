{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqRHyNzdeXaS"
      },
      "source": [
        "# Minimal Transformer: Next Token Prediction\n",
        "\n",
        "In this notebook, we build a minimal decoder-only transformer architecture (similar to GPT) and train it on next token prediction. This follows your previous class on attention mechanisms.\n",
        "\n",
        "**Key differences from encoder-decoder transformers:**\n",
        "- Decoder-only architecture (no encoder)\n",
        "- Causal self-attention (can only attend to previous tokens)\n",
        "- Next token prediction objective\n",
        "- Character-level tokenization for simplicity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl40akxCeXaU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPu9uTHTeXaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d22db4-b079-4939-d28e-8aea2c44deff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "PyTorch version: 2.9.0+cu126\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgcbOVzneXaV"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "We keep the model small so it can train quickly in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qlf2t7UpeXaV"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "class Config:\n",
        "    # Model architecture\n",
        "    d_model = 128          # Embedding dimension\n",
        "    n_heads = 4            # Number of attention heads\n",
        "    n_layers = 4           # Number of transformer blocks\n",
        "    d_ff = 512             # Feed-forward dimension\n",
        "    dropout = 0.1          # Dropout rate\n",
        "\n",
        "    # Training\n",
        "    block_size = 64        # Maximum context length\n",
        "    batch_size = 64        # Batch size\n",
        "    learning_rate = 3e-4   # Learning rate\n",
        "    max_iters = 3000       # Training iterations\n",
        "    eval_interval = 300    # Evaluate every N iterations\n",
        "    eval_iters = 100       # Number of iterations for evaluation\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR0RtnS0eXaV"
      },
      "source": [
        "## Data: Choose Your Dataset\n",
        "\n",
        "Select one of the following datasets by uncommenting the corresponding option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x_tHC_aheXaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb8052b-d84e-4b6f-b96a-36385023a5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading TinyStories dataset...\n",
            "Dataset length: 1,000,000 characters\n",
            "\n",
            "First 500 characters:\n",
            "\n",
            "Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw many amazing things, like beautiful vases that were on display in a store. One day, Ben was walking through the store when he came across a very special vase. When Ben saw it he was amazed!  \n",
            "He said, “Wow, that is a really amazing vase! Can I buy it?” \n",
            "The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends how amazing it is!”\n",
            "So Ben took the vase home\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# OPTION 1: TinyStories (Recommended - Modern, Simple English)\n",
        "# ============================================================\n",
        "# Download a subset of TinyStories dataset\n",
        "print(\"Downloading TinyStories dataset...\")\n",
        "url = 'https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt'\n",
        "urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "\n",
        "# Read only first ~1MB (similar to Shakespeare size)\n",
        "with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read(1_000_000)  # Read first 1 million characters\n",
        "\n",
        "print(f'Dataset length: {len(text):,} characters')\n",
        "print(f'\\nFirst 500 characters:')\n",
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsKL3PKueXaV"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 2: Shakespeare (Classic - Early Modern English)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Shakespeare instead:\n",
        "\n",
        "# print(\"Downloading Shakespeare dataset...\")\n",
        "# url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "#\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read()\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9BUMz4xeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 3: Python Code\n",
        "# ============================================================\n",
        "# Uncomment these lines to train on Python code:\n",
        "\n",
        "# print(\"Downloading Python code dataset...\")\n",
        "# url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/linux/input.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "#\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read(1_000_000)  # Read first 1 million characters\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74BplMxLeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 4: Modern Novel (e.g., The Adventures of Sherlock Holmes)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Sherlock Holmes:\n",
        "\n",
        "# print(\"Downloading Sherlock Holmes...\")\n",
        "# url = 'https://www.gutenberg.org/files/1661/1661-0.txt'\n",
        "# urllib.request.urlretrieve(url, 'dataset.txt')\n",
        "#\n",
        "# with open('dataset.txt', 'r', encoding='utf-8') as f:\n",
        "#     text = f.read()\n",
        "#\n",
        "# # Remove Project Gutenberg header/footer\n",
        "# start = text.find('I.')\n",
        "# end = text.find('End of the Project Gutenberg')\n",
        "# if start != -1 and end != -1:\n",
        "#     text = text[start:end]\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')\n",
        "# print(f'\\nFirst 500 characters:')\n",
        "# print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3rMxw8TeXaW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTION 5: Wikipedia Article (Simple English Wikipedia)\n",
        "# ============================================================\n",
        "# Uncomment these lines to use Wikipedia:\n",
        "\n",
        "# print(\"Downloading Wikipedia dump...\")\n",
        "# # This is a small subset of Simple English Wikipedia\n",
        "# url = 'https://dumps.wikimedia.org/simplewiki/latest/simplewiki-latest-pages-articles.xml.bz2'\n",
        "# # Note: This requires additional processing with packages like mwparserfromhell\n",
        "# # For simplicity, you might want to manually download a few Wikipedia articles as .txt\n",
        "# # Or use a pre-processed Wikipedia dataset\n",
        "#\n",
        "# # For a quick demo, here's a manual approach:\n",
        "# text = \"\"\"Wikipedia is a free online encyclopedia.\n",
        "# [Paste several Wikipedia articles here as plain text]\n",
        "# \"\"\"\n",
        "#\n",
        "# print(f'Dataset length: {len(text):,} characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAg1Ed3DeXaW"
      },
      "source": [
        "## Character-Level Tokenization\n",
        "\n",
        "For simplicity, we use character-level tokenization. Each unique character becomes a token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UNRV7YDYeXaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbaa9ad-aceb-436e-9937-3091bda8589f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 76 unique characters\n",
            "Characters: \n",
            " !\"',-.01389:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz|–—’“”\n",
            "\n",
            "Original: Hello, world!\n",
            "Encoded: [25, 48, 55, 55, 58, 5, 1, 66, 58, 61, 55, 47, 2]\n",
            "Decoded: Hello, world!\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(f'Vocabulary size: {vocab_size} unique characters')\n",
        "print(f'Characters: {\"\".join(chars)}')\n",
        "\n",
        "# Create character-to-integer and integer-to-character mappings\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encoder: string -> list of integers\n",
        "def encode(s):\n",
        "    return [char_to_idx[c] for c in s]\n",
        "\n",
        "# Decoder: list of integers -> string\n",
        "def decode(ids):\n",
        "    return ''.join([idx_to_char[i] for i in ids])\n",
        "\n",
        "# Test\n",
        "test_str = \"Hello, world!\"\n",
        "encoded = encode(test_str)\n",
        "decoded = decode(encoded)\n",
        "print(f'\\nOriginal: {test_str}')\n",
        "print(f'Encoded: {encoded}')\n",
        "print(f'Decoded: {decoded}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qo1LW5teXaW"
      },
      "source": [
        "## Prepare Training Data\n",
        "\n",
        "Split into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r7dMypRueXaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5007d2-38fe-47ec-8814-edf41f4b82ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded data shape: torch.Size([1000000])\n",
            "Train data: 900,000 tokens\n",
            "Val data: 100,000 tokens\n"
          ]
        }
      ],
      "source": [
        "# Encode the entire dataset\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(f'Encoded data shape: {data.shape}')\n",
        "\n",
        "# Train/validation split (90/10)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(f'Train data: {len(train_data):,} tokens')\n",
        "print(f'Val data: {len(val_data):,} tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3RyRVUFeXaX"
      },
      "source": [
        "## Data Batching\n",
        "\n",
        "Create batches of sequences for training. Each sequence is `block_size` tokens long."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aVGjjJw6eXaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d47a00-8324-4f64-9d40-218fc2aff566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch shape: torch.Size([64, 64])\n",
            "Target batch shape: torch.Size([64, 64])\n",
            "\n",
            "Example sequence:\n",
            "Input:  irl named Sue. Sue loved to look at pretty things. She would adm\n",
            "Target: rl named Sue. Sue loved to look at pretty things. She would admi\n"
          ]
        }
      ],
      "source": [
        "def get_batch(split, config):\n",
        "    \"\"\"\n",
        "    Generate a small batch of data of inputs x and targets y.\n",
        "\n",
        "    Args:\n",
        "        split: 'train' or 'val'\n",
        "        config: Configuration object\n",
        "\n",
        "    Returns:\n",
        "        x: Input sequences [batch_size, block_size]\n",
        "        y: Target sequences [batch_size, block_size]\n",
        "    \"\"\"\n",
        "    data = train_data if split == 'train' else val_data\n",
        "\n",
        "    # Randomly select starting positions\n",
        "    ix = torch.randint(len(data) - config.block_size, (config.batch_size,))\n",
        "\n",
        "    # Create input and target sequences\n",
        "    x = torch.stack([data[i:i+config.block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+config.block_size+1] for i in ix])\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "# Test batch generation\n",
        "x_batch, y_batch = get_batch('train', config)\n",
        "print(f'Input batch shape: {x_batch.shape}')\n",
        "print(f'Target batch shape: {y_batch.shape}')\n",
        "print(f'\\nExample sequence:')\n",
        "print(f'Input:  {decode(x_batch[0].tolist())}')\n",
        "print(f'Target: {decode(y_batch[0].tolist())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMQUsaI4eXaX"
      },
      "source": [
        "## Model Components\n",
        "\n",
        "Now we build the transformer architecture from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92Q5uwjeXaX"
      },
      "source": [
        "### 1. Multi-Head Attention\n",
        "\n",
        "You've already learned about attention! This is the causal (masked) version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Pc_JggyeXaX"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head causal self-attention.\n",
        "\n",
        "    Key difference from your previous class:\n",
        "    - Uses a causal mask to prevent attending to future tokens\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads  # Dimension per head\n",
        "\n",
        "        # Linear projections for Q, K, V (all heads at once)\n",
        "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "        # Output projection\n",
        "        self.W_o = nn.Linear(d_model, d_model, bias=False) # ouput\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, d_model]\n",
        "\n",
        "        Returns:\n",
        "            Output tensor [batch_size, seq_len, d_model]\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.W_q(x)  # [batch_size, seq_len, d_model]\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "        # Split into multiple heads and reshape\n",
        "        # [batch_size, seq_len, d_model] -> [batch_size, seq_len, n_heads, d_k]\n",
        "        # -> [batch_size, n_heads, seq_len, d_k]\n",
        "        Q = Q.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_len, self.n_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        # [batch_size, n_heads, seq_len, seq_len]\n",
        "\n",
        "        # Apply causal mask (prevent attending to future tokens)\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device)).bool()\n",
        "        scores = scores.masked_fill(~mask, float('-inf'))\n",
        "\n",
        "        # Apply softmax\n",
        "        attn_weights = F.softmax(scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Apply attention to values\n",
        "        out = torch.matmul(attn_weights, V)\n",
        "        # [batch_size, n_heads, seq_len, d_k]\n",
        "\n",
        "        # Concatenate heads\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
        "\n",
        "        # Output projection\n",
        "        out = self.W_o(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtzEzEBceXaX"
      },
      "source": [
        "### 2. Feed-Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TegCotmAeXaX"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Position-wise Feed-Forward Network.\n",
        "    Two linear transformations with GELU activation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrXl0BdfeXaX"
      },
      "source": [
        "### 3. Transformer Block\n",
        "\n",
        "Combines attention and feed-forward with residual connections and layer normalization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "golNGPNNeXaX"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single transformer block:\n",
        "    - Multi-head attention with residual connection\n",
        "    - Feed-forward network with residual connection\n",
        "    - Layer normalization (pre-norm architecture)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention(d_model, n_heads, dropout)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre-norm architecture (more stable training)\n",
        "        # Attention with residual\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        # Feed-forward with residual\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1LD_n9eXaX"
      },
      "source": [
        "### 4. Complete Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e9pl_dLteXaY"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    A minimal GPT-style transformer for next token prediction.\n",
        "\n",
        "    Architecture:\n",
        "    1. Token embeddings + positional embeddings\n",
        "    2. Stack of transformer blocks\n",
        "    3. Layer norm\n",
        "    4. Linear head to predict next token\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Token embeddings\n",
        "        self.token_embedding = nn.Embedding(vocab_size, config.d_model)\n",
        "\n",
        "        # Positional embeddings (learned)\n",
        "        self.pos_embedding = nn.Embedding(config.block_size, config.d_model)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(config.d_model, config.n_heads, config.d_ff, config.dropout)\n",
        "            for _ in range(config.n_layers)\n",
        "        ])\n",
        "\n",
        "        # Final layer norm\n",
        "        self.ln_f = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        # Language modeling head\n",
        "        self.lm_head = nn.Linear(config.d_model, vocab_size, bias=False)\n",
        "\n",
        "        # Weight tying (share weights between token embeddings and lm_head)\n",
        "        self.token_embedding.weight = self.lm_head.weight\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        # Report number of parameters\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Number of parameters: {n_params/1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: Input token indices [batch_size, seq_len]\n",
        "            targets: Target token indices [batch_size, seq_len] (optional)\n",
        "\n",
        "        Returns:\n",
        "            logits: Output logits [batch_size, seq_len, vocab_size]\n",
        "            loss: Cross-entropy loss (if targets provided)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len = idx.shape\n",
        "\n",
        "        # Token embeddings\n",
        "        tok_emb = self.token_embedding(idx)  # [batch_size, seq_len, d_model]\n",
        "\n",
        "        # Positional embeddings\n",
        "        pos = torch.arange(0, seq_len, dtype=torch.long, device=idx.device)\n",
        "        pos_emb = self.pos_embedding(pos)  # [seq_len, d_model]\n",
        "\n",
        "        # Add embeddings\n",
        "        x = tok_emb + pos_emb  # Broadcasting happens automatically\n",
        "\n",
        "        # Apply transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Final layer norm\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Language modeling head\n",
        "        logits = self.lm_head(x)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Compute loss if targets are provided\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            # Reshape for cross-entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits_flat = logits.view(B * T, C)\n",
        "            targets_flat = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Generate new tokens autoregressively.\n",
        "\n",
        "        Args:\n",
        "            idx: Starting sequence [batch_size, seq_len]\n",
        "            max_new_tokens: Number of tokens to generate\n",
        "            temperature: Sampling temperature (higher = more random)\n",
        "            top_k: If set, only sample from top k tokens\n",
        "\n",
        "        Returns:\n",
        "            Generated sequence [batch_size, seq_len + max_new_tokens]\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop context if needed (to fit block_size)\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "\n",
        "            # Forward pass\n",
        "            logits, _ = self(idx_cond)\n",
        "\n",
        "            # Focus on last time step\n",
        "            logits = logits[:, -1, :] / temperature  # [batch_size, vocab_size]\n",
        "\n",
        "            # Optionally crop logits to only top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            # Append to sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7cO8INdeXaY"
      },
      "source": [
        "## Create Model Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NB1caQEYeXaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3976d4-d250-4197-c9de-bdacf394b095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 0.81M\n",
            "GPTModel(\n",
            "  (token_embedding): Embedding(76, 128)\n",
            "  (pos_embedding): Embedding(64, 128)\n",
            "  (blocks): ModuleList(\n",
            "    (0-3): 4 x TransformerBlock(\n",
            "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (W_k): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (W_v): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (W_o): Linear(in_features=128, out_features=128, bias=False)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "          (3): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=128, out_features=76, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "model = GPTModel(vocab_size, config).to(device)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7WpUSDReXaY"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qdUzOKiLeXaY"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model, config):\n",
        "    \"\"\"\n",
        "    Estimate loss on train and validation sets.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(config.eval_iters)\n",
        "        for k in range(config.eval_iters):\n",
        "            X, Y = get_batch(split, config)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vPYav8veXaY"
      },
      "source": [
        "## Test Generation Before Training\n",
        "\n",
        "Let's see what the untrained model generates (should be gibberish)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LXb0hwe0eXaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f0d348-5a7e-4c3d-cc21-85c45afb62fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Untrained Model Generation ===\n",
            "\n",
            "Qe–GjPkC88X“GQYx3dJcQjm8vQIgXXX“HFswPXdd|8cPUYvXVQ?88|w|L|XX8mY;\n",
            "soKQH9XKDhWoKs88josrdXX8H31  \n",
            "HXP8s\n",
            "8\n",
            "Qw?\n",
            "3T——9XccHXP9tcE9;UXUPjTTUXUUUQoQs–ddyDzUrXsowsccXcxHPss8UV888HHUUllcPXXc\n",
            "QI”PjPPXXXPooQX9D\n",
            "Hc\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate from untrained model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=200, temperature=1.0, top_k=10)\n",
        "print('\\n=== Untrained Model Generation ===')\n",
        "print(decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HyKi3XzeXaZ"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "Train for a few thousand iterations. Even this limited training should show improvement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "C_c_4azWeXaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "eed3ecfdd7734bfaae4f30e168205bae",
            "08d8e64ae80b46ea875b27ee92e4d371",
            "5efbd4bc7bbc4e1ab20464c063d54e16",
            "8573b4cf35c24407afaaeacfa6e05d00",
            "57527f603c7c494dbe05e03c2ff264e9",
            "33e21291f84e4727bed6d9c1fa9effcd",
            "06b1f026af564a0b90204dd73f99332f",
            "ba023ea1e83440d7b0dfd6d7e1b9c3a5",
            "2bd12dca262d42b3bb9502d46101c5f1",
            "91233e7b7e304ed190b2a0aad691167b",
            "e97f5fd27b474b88b5883bc50fce903b"
          ]
        },
        "outputId": "fdfe052e-d8ae-42fd-d3a8-5d4203e15832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Training for 3000 iterations\n",
            "Evaluating every 300 iterations\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eed3ecfdd7734bfaae4f30e168205bae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: train loss 4.3775, val loss 4.3766\n",
            "Step 300: train loss 2.0615, val loss 2.0763\n",
            "Step 600: train loss 1.5952, val loss 1.5991\n",
            "Step 900: train loss 1.3856, val loss 1.3965\n",
            "Step 1200: train loss 1.2567, val loss 1.2717\n",
            "Step 1500: train loss 1.1919, val loss 1.2203\n",
            "Step 1800: train loss 1.1419, val loss 1.1692\n",
            "Step 2100: train loss 1.0972, val loss 1.1293\n",
            "Step 2400: train loss 1.0673, val loss 1.1061\n",
            "Step 2700: train loss 1.0380, val loss 1.0804\n",
            "Step 2999: train loss 1.0174, val loss 1.0608\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "iterations = []\n",
        "\n",
        "print('Starting training...')\n",
        "print(f'Training for {config.max_iters} iterations')\n",
        "print(f'Evaluating every {config.eval_interval} iterations\\n')\n",
        "\n",
        "for iter in tqdm(range(config.max_iters)):\n",
        "    # Evaluate loss periodically\n",
        "    if iter % config.eval_interval == 0 or iter == config.max_iters - 1:\n",
        "        losses = estimate_loss(model, config)\n",
        "        print(f\"Step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['val'])\n",
        "        iterations.append(iter)\n",
        "\n",
        "    # Sample a batch\n",
        "    xb, yb = get_batch('train', config)\n",
        "\n",
        "    # Forward pass\n",
        "    logits, loss = model(xb, yb)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print('\\nTraining complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_0vqfleXaZ"
      },
      "source": [
        "## Plot Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LqGP8XgTeXaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "deee5298-d348-409a-e741-6b12fd3a5117"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial train loss: 4.3775\n",
            "Final train loss: 1.0174\n",
            "Improvement: 3.3601\n"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(iterations, train_losses, label='Train Loss', marker='o')\n",
        "plt.plot(iterations, val_losses, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f'Initial train loss: {train_losses[0]:.4f}')\n",
        "print(f'Final train loss: {train_losses[-1]:.4f}')\n",
        "print(f'Improvement: {train_losses[0] - train_losses[-1]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nVqySQNeXaZ"
      },
      "source": [
        "## Test Generation After Training\n",
        "\n",
        "Now let's see what the trained model generates!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bBZHhCcxeXaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0f66b8-de50-4822-cd07-7ca8c7d2e227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Trained Model Generation ===\n",
            "\n",
            "\n",
            "Tom was going to the stall and swomped at the tree. They had a fun food and finished hiceaming. Tim loved to play her.\n",
            "Max celearned and they went to the park. So, Tim says, \"I am your friend my dad. You happy. I am an had a lot of fun.\" The cat was so happy and became because her friends. And that is m still hard and learned help. Lucy saw Max wanted to see was. He takes fun. He wanted to the big hoper the pater and truck.\n",
            "Sue said, \"That harn you?\"\n",
            "But Maybe were happy. They loved to play tog\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate from trained model\n",
        "model.eval()\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated = model.generate(context, max_new_tokens=500, temperature=1.0, top_k=10)\n",
        "print('\\n=== Trained Model Generation ===')\n",
        "print(decode(generated[0].tolist()))\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALD6FR6PeXaZ"
      },
      "source": [
        "## Generation with Different Seeds\n",
        "\n",
        "Try starting with different prompts. Adjust these based on your dataset!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "J1ezJoOZeXaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3d3d92-5906-4b27-f8a3-14844b8b0a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Prompt: \"Once upon a time\" ===\n",
            "Once upon a time, there was a little boy named Tom. Tim wanted to look laugh and tlow. The blue found a nice on the story. He would brave around a little house. The crab loved to play with her pappiles and cares and \n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"One day, a little\" ===\n",
            "One day, a little girl named Jack. They lived had fun together and pulled up and loved time, something in the park ball. In the right are who was scared and started to lost. She was very happy together in his friend. \n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"There was a\" ===\n",
            "There was a big bird in the sky and were carefully.\n",
            "<|endoftext|>\n",
            "Once upon a time, there was a little dog named Tim. But loved to play with his mom and dad.\n",
            "One day, they felt happy to being the ball to the par\n",
            "==================================================\n",
            "\n",
            "=== Prompt: \"The girl was\" ===\n",
            "The girl was so his mom and said, \"I can have the door and didn't understand?\"\n",
            "Sara and Sam felt sad. She was surprised and balls to come from hight.\n",
            "One day, they found a stead holes of fun the firest come and t\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def generate_with_prompt(prompt, max_new_tokens=300, temperature=0.8, top_k=10):\n",
        "    \"\"\"\n",
        "    Generate text starting from a prompt.\n",
        "    \"\"\"\n",
        "    context = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
        "    generated = model.generate(context, max_new_tokens=max_new_tokens,\n",
        "                             temperature=temperature, top_k=top_k)\n",
        "    return decode(generated[0].tolist())\n",
        "\n",
        "# Choose prompts based on your dataset:\n",
        "\n",
        "# For TinyStories:\n",
        "prompts = [\n",
        "    \"Once upon a time\",\n",
        "    \"One day, a little\",\n",
        "    \"There was a\",\n",
        "    \"The girl was\"\n",
        "]\n",
        "\n",
        "# For Shakespeare:\n",
        "# prompts = [\n",
        "#     \"ROMEO:\\n\",\n",
        "#     \"To be or not to be\",\n",
        "#     \"First Citizen:\\n\",\n",
        "#     \"The king\"\n",
        "# ]\n",
        "\n",
        "# For Python code:\n",
        "# prompts = [\n",
        "#     \"def \",\n",
        "#     \"import \",\n",
        "#     \"class \",\n",
        "#     \"for i in\"\n",
        "# ]\n",
        "\n",
        "# For Sherlock Holmes:\n",
        "# prompts = [\n",
        "#     \"Sherlock Holmes\",\n",
        "#     \"The detective\",\n",
        "#     \"Watson said\",\n",
        "#     \"It was a\"\n",
        "# ]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f'\\n=== Prompt: \"{prompt}\" ===')\n",
        "    generated_text = generate_with_prompt(prompt, max_new_tokens=200)\n",
        "    print(generated_text)\n",
        "    print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcbOR0dteXaZ"
      },
      "source": [
        "## Temperature and Top-K Effects\n",
        "\n",
        "Experiment with different generation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PATeFcuCeXaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd94db4-d573-4c60-cf99-6888800c9022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Low Temperature (0.5) - More focused ===\n",
            "Once upon a time, there was a big tree with a big ball. They liked to play with the park. They would be his friends and saw a big cat named Tim. The cat was very happ\n",
            "\n",
            "=== Medium Temperature (1.0) - Balanced ===\n",
            "Once upon a time, there was a big dog named Sara. Shedia listened to play with her friend. But he would frievy the tastame closer and played up teak our friend, a big\n",
            "\n",
            "=== High Temperature (1.5) - More random ===\n",
            "Once upon a time, there was a little boy. Mor. The clan askest. Lucy and Brearry.\n",
            "Mia didn't understen the tlable in the swongs.\n",
            "Smo shraked it inside. She liked to p\n"
          ]
        }
      ],
      "source": [
        "# Choose a prompt from your dataset:\n",
        "prompt = \"Once upon a time\"  # For TinyStories\n",
        "# prompt = \"ROMEO:\\n\"  # For Shakespeare\n",
        "# prompt = \"def \"  # For Python code\n",
        "# prompt = \"Sherlock Holmes\"  # For Sherlock Holmes\n",
        "\n",
        "print(\"=== Low Temperature (0.5) - More focused ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=0.5, top_k=10))\n",
        "\n",
        "print(\"\\n=== Medium Temperature (1.0) - Balanced ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=1.0, top_k=10))\n",
        "\n",
        "print(\"\\n=== High Temperature (1.5) - More random ===\")\n",
        "print(generate_with_prompt(prompt, max_new_tokens=150, temperature=1.5, top_k=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vguoqWQ1eXaZ"
      },
      "source": [
        "## Analysis: What Did We Learn?\n",
        "\n",
        "Even with this minimal training:\n",
        "1. **Structure**: The model learns basic text structure (words, punctuation, capitalization)\n",
        "2. **Patterns**: It picks up on common patterns in the data\n",
        "   - TinyStories: narrative structure, character actions\n",
        "   - Shakespeare: dialogue format, character names\n",
        "   - Python code: syntax, indentation, function structure\n",
        "3. **Context**: The causal attention allows it to use context from previous tokens\n",
        "4. **Limitations**: It's not perfect - longer coherence requires much more training\n",
        "\n",
        "**Key Architecture Points:**\n",
        "- **Decoder-only**: Unlike encoder-decoder models for translation, this is decoder-only (like GPT)\n",
        "- **Causal attention**: The mask ensures we only attend to past tokens\n",
        "- **Next token prediction**: Simple but powerful objective\n",
        "- **Scalability**: This same architecture scales to billions of parameters (GPT-3, GPT-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzmVKYZheXaZ"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "To improve this model further, try one or multiple of the following:\n",
        "1. Train for more iterations (10k-50k)\n",
        "2. Increase model size (more layers, larger d_model)\n",
        "3. Combine datasets together to have more text (be careful of style differences)\n",
        "4. Add learning rate scheduling\n",
        "5. Modify the optimizer and hyperparameters\n",
        "6. Implement gradient clipping\n",
        "7. Try different tokenization (BPE instead of character-level)\n",
        "8. Add dropout for better regularization\n",
        "9. Experiment with different attention patterns (e.g., Flash Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVFo9a-HeXaa"
      },
      "source": [
        "## Save Model (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdQWTUaleXaa"
      },
      "outputs": [],
      "source": [
        "# Save model checkpoint\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'config': config,\n",
        "    'vocab_size': vocab_size,\n",
        "    'char_to_idx': char_to_idx,\n",
        "    'idx_to_char': idx_to_char,\n",
        "}, 'minimal_transformer_checkpoint.pt')\n",
        "\n",
        "print('Model saved to minimal_transformer_checkpoint.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l1wz2CPeXaa"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, we built a minimal transformer from scratch:\n",
        "- Character-level tokenization\n",
        "- Causal multi-head attention\n",
        "- Position-wise feed-forward networks\n",
        "- Residual connections and layer normalization\n",
        "- Next token prediction training\n",
        "- Autoregressive generation\n",
        "\n",
        "This architecture is the foundation of modern LLMs like GPT!\n",
        "\n",
        "**Questions to consider:**\n",
        "1. Why is causal masking necessary for language generation?\n",
        "2. What would happen without positional embeddings?\n",
        "3. How does temperature affect generation quality?\n",
        "4. What are the tradeoffs between character-level and subword tokenization?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eed3ecfdd7734bfaae4f30e168205bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08d8e64ae80b46ea875b27ee92e4d371",
              "IPY_MODEL_5efbd4bc7bbc4e1ab20464c063d54e16",
              "IPY_MODEL_8573b4cf35c24407afaaeacfa6e05d00"
            ],
            "layout": "IPY_MODEL_57527f603c7c494dbe05e03c2ff264e9"
          }
        },
        "08d8e64ae80b46ea875b27ee92e4d371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33e21291f84e4727bed6d9c1fa9effcd",
            "placeholder": "​",
            "style": "IPY_MODEL_06b1f026af564a0b90204dd73f99332f",
            "value": "100%"
          }
        },
        "5efbd4bc7bbc4e1ab20464c063d54e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba023ea1e83440d7b0dfd6d7e1b9c3a5",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bd12dca262d42b3bb9502d46101c5f1",
            "value": 3000
          }
        },
        "8573b4cf35c24407afaaeacfa6e05d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91233e7b7e304ed190b2a0aad691167b",
            "placeholder": "​",
            "style": "IPY_MODEL_e97f5fd27b474b88b5883bc50fce903b",
            "value": " 3000/3000 [00:55&lt;00:00, 78.02it/s]"
          }
        },
        "57527f603c7c494dbe05e03c2ff264e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e21291f84e4727bed6d9c1fa9effcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b1f026af564a0b90204dd73f99332f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba023ea1e83440d7b0dfd6d7e1b9c3a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd12dca262d42b3bb9502d46101c5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91233e7b7e304ed190b2a0aad691167b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97f5fd27b474b88b5883bc50fce903b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}